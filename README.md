# Silentalk :wave: :love_you_gesture:

![icon](https://github.com/user-attachments/assets/5790484d-6158-4029-b2c6-8954db1b018f)

Approximately 400+ million people worldwide experience hearing impairments, creating significant barriers to communication in social and professional settings. While sign language is a vital tool for interaction, its limited understanding among the public results in challenges for sign language users.

SilenTalk offers an innovative solution: a real-time sign language-to-text and audio translation system. Using YOLOv5 for gesture detection and a sequence-to-sequence NLP model for sentence formation, the platform processes live webcam input with 95% gesture recognition accuracy and a BLEU score of 82% for textual outputs.

Built with PyTorch, TensorFlow, and Django, the system is optimized for real-time performance on standard hardware, requiring only a webcam. Challenges such as gesture variability and sentence fluency were overcome through dataset expansion and enhanced NLP modeling, ensuring a robust and user-friendly experience.

User feedback underscores SilenTalk's effectiveness in enabling seamless communication and fostering inclusivity. With plans for multi-language support and mobile integration, this project aims to further empower the hearing-impaired community and reduce communication barriers.


